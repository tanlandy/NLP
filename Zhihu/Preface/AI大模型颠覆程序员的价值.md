# Goal

一个观点
一个底层技术
两个应用

AGI：通用人工智能

# 1 - 企业借助大模型获得业务增长的可能性

企业如何提升收入：只有很少的生意可以重做一遍，但有一些新的生意和业务，过去没得做，现在有得做了。

比如评语小工具，画室老师使用AI来给学生画作撰写评语，全国1000多月付费几十元的用户。

第一阶：指令工程：总结经验，在不同场景下提升效果
第二阶：向量数据库，向量检索，Langchain，RAG，SK，智能体MetaGPT
第三阶：有些场景下还是不行，通用知识多，垂直领域低：在专业场景进行微调

# 2 - 过去驾驭AI技术到底都要掌握些什么

## Attention is all you need

编码器：将输入序列转换为隐藏状态序列
解码器：将隐藏状态序列转换为输出序列。一次生成一个元素（每个元素512维），每一步都是自回归的，在生成下一个元素时，使用先前生成的元素作为附加输入。

Input Embedding：将输入序列转换为向量序列，每个向量512维

模型是什么：

1. 一大堆公式
2. 一大堆参数

GPT3.5参数量175B

编码器：把输入的话映射到新的语义空间

K矩阵：每个词的语义向量，类似于人类的字典

Q矩阵：输入的话的语义向量

V矩阵：K和Q相似度计算出来的权重

注意力机制：把输入的话映射到新的语义空间，每个词都有一个权重，权重越大，说明这个词对于输入的话的语义影响越大。

- V矩阵：每个字和词都有权重数值

相比一开始的注意力机制，升级到自注意力机制，模型的构建过程中，不做额外的处理

多模态：多种输入，比如图像和文本。

# 3 - 现在驾驭AI技术门槛低到了什么程度

# 4 - Fine-tune

![Fine-tune-step-OPENAI](<Screenshot 2024-01-26 at 10.45.40 AM.png>)

本地的微调：

第一步：2个人，3周时间就够了：教专业知识，一次就够了
GPT-3训练时使用了13k条一问一答的数据

第二步：RM
GPT-3训练时使用了33k条一问多答然后挑出一个好的数据

第三步：利用RM进行强化学习

二三循环多次：调教表达方式，知识已经够了，但是表达方式不够好，需要多次调教

可以预估出来一个月可以攒多少条human feedback
Mid journey一次性生成4张图，选择一张可以生成其高清版本，这也相当于收到了一条人类反馈human feedback

![Fine-tuning-paper](<Screenshot 2024-01-26 at 1.46.19 PM.png>)

国内大多数公司Fine tune路线：

1. 选一个开源的模型
2. 自己准备数据
3. 整一个开源的fine tune的代码
4. 在自己的服务器上做fine tune，整个过程数据没有出服务器
5. 最后用一张显卡就可以做私有化部署

Alpaca就是由LLaMa 7B微调得到的全新模型，仅用了52k数据，性能约等于GPT-3.5，175B
在8个80G的A100上训练了3个小时，100刀
生成数据使用OpenAI的API，500刀

目前根据复杂度，最多应用的是13B, 33B, 65B

最重要的两个东西
Transformers
Alpaca训练过程

现在的问题：
老板们畅想很多，一顿畅想，做不出决策 -> 缺决策依据 -> 缺少一个可以把整个过程讲清楚的人 -> 讲清楚以下内容

1. 讲了很多场景，这个场景相对靠谱，哪个场景相对不那么靠谱，原因是什么
2. 在相对靠谱的一两个场景下，在现有的全世界科技水平下，我们投入少量人力，大概其能做到什么样的效果
3. 这个场景，如果要做简单的人力和投入，大概其要用到第一阶第二阶第三阶的哪些技术，可能是某个技术，某些技术，甚至和传统技术的组合
4. 组织什么样的团队去做
5. 具体的周期是什么样（45一起：第一步，3个运营的同事，3周组织数据到什么样的数据量级，还要在企业微信聊天记录做什么样的抽取，用什么工具做数据过滤，如何定义好数据和不好数据；第二步，需要几个什么样的工程师，经过第一轮的Fine tune，3周就得到第一个版本了；第三步，经过内部的使用，进行标记，二三二三循环调教；第四步，在企业微信聊天框等，一个月能收集多少条人类反馈。重复二三四步，模型可以得到如何的进化，达到什么样的效果）
6. 讨论商业化，ToC ToB如何赚钱，找客户调研，预估赚钱的量级，投入成本也清晰可算，这样公司起码可以做决策了

只需要自己见多识广，知道现有的科技可以做到什么样的效果

这个角色可以叫大模型产品经理，大模型解决方案专家

方法：把三阶的技术多玩玩，能把事情讲清楚

# 课程重点

Prompt: few shot和思维链思维树，做到调教AI，不仅仅是和AI聊天
RAG：向量数据库与向量检索
手撕AutoGPT：大模型未来的应用，基本上都要用到智能体。目前有两个，一个是AutoGPT，一个是MetaGPT
Fine-tune：第一节学会训练GPT，第二节学会训练垂类模型

# 目标

作为公司最懂大模型的人，提升在组织中的生态位

## 大模型岗位推荐

大模型训练师
大模型算法工程师
大模型研发工程师
-> 传统的算法多数都用不上

问题归类：大模型的能力
翻译SQL：大模型的能力
产生回复：大模型生成 + 相关数据扣出来，从SQL中找到相关的数据，然后填进去

医疗教育金融，目前全世界在AI大模型投入最大的三个领域
