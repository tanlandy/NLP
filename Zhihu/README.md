# Todo list

DONE 看02Prompt

DONE 看03从AI编程认知AI

DONE 第五期看05RAG 和 Embeddings，给RAG项目

DONE 看07LangChain，

DONE 看09LLM 应用开发工具链，更新05项目

DONE 看10手撕 Agent 实现 AutoGPT，更新06项目

DONE 看RAG讲座

DONE 第四期看11模型微调上，给微调项目

DONE 第四期看12模型微调下

DONE 看微调讲座

# 项目相关

## 项目一

简介：LLaMa2/Gemma微调

详细内容：

突出要点：Fine-tune

## 项目二

简介：aitutor问答

详细内容：
基于RAG的Chatbot多轮对话

- 处理企业知识库文档，尝试多种文档切分方式进行切分，选定向量化模型对其进行向量化处理
- 配置Milvus的数据模式，将向量化的知识库文档数据灌入Milvus向量数据库，构建ANNS索引
- 编写基于RRF检索后排序（融合排序）算法，使用关键词搜索与向量检索相结合的混合检索方式，对知识库文档问答的用户输入进行RAG的检索增强
- 相比使用模型通用能力，使用RAG后，模型输出更加自然、准确

突出要点：RAG

## 项目三

简介：雅思口语模拟考官

详细内容：

项目介绍：使用LLaMa2和

突出要点：Prompt工程

# 草稿

GPT4调优实现近期话题的问答(OpenAI, GPT4, Embedded-Search)                                  04.2023 - 06.2023
• 利用嵌入式搜索对OpenAI的GPT模型进行优化，使其能正确回答2021.9之后事件（如卡塔尔世界杯、北京冬奥会、俄乌冲突等）的问题
• 数据处理：在维基百科爬取962篇卡塔尔世界杯条目，按1600 tokens大小进行分割并向量化
• 模型处理：向量化用户问题语句，计算并排序得到最相关的数据，将其作为整体作为Prompt
• 结果：能正确回答诸如赛事介绍、参赛队伍、上场人物、比赛结果、冠军历程等信息

LLM大模型微调与应用(Deep Learning, Large Language Model, Prompt)                      01.2023 - 04.2023
• 使用大语言模型低秩适配LoRA技术，微调FLAN-T5模型，实现文本生成功能
• 预处理samsum数据集，使用Peft降低大模型所需内存，使用Transformers库填充输入和标签并定义训练超参
• 训练模型，保存到Hugging Face Hub，实现文本摘要生成功能

Chatbot多轮对话AI机器人(PyTorch, Machine Learning, Seq2seq)                                   09.2022 - 12.2022
• 利用康奈尔电影数据集，构建闲聊机器人，实现对话功能
• 数据处理：下载并预处理数据集，调整格式、分词、长度，拆分为查询语句和响应语句
• 模型建立：参考Luong的全局注意力机制，编写编码、解码层、注意力层代码训练模型
• 结果：在电影领域，实现智能机器人的对话功能

公司下
• 在Django框架下，利用规则和MySQL数据库，编写Rule-based英语作文语法分析算法
• 利用PyTorch建立Transformer的T5-base模型，自动化生成英语作文的文本摘要
• 优化已有的英语作文体裁识别算法，测试文本体裁识别运行时间缩短33%，准确率提升5%
