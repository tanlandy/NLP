# Todo list

DONE 看02Prompt

DONE 看03从AI编程认知AI

DONE 第五期看05RAG 和 Embeddings，给RAG项目

DONE 看07LangChain，

DONE 看09LLM 应用开发工具链，更新05项目

DONE 看10手撕 Agent 实现 AutoGPT，更新06项目

DONE 看RAG讲座

DONE 第四期看11模型微调上，给微调项目

DONE 第四期看12模型微调下

DONE 看微调讲座

# 项目相关

## 项目零

简介：DPO对齐微调，使其更符合

## 项目一

简介：基于Mistral-7B基座模型的微调

详细内容：

- 在消费级显卡（RTX-4090）上，使用teknium/OpenHermes-2.5数据集（经处理后共10k条数据），对Mistral-7B-v0.1模型进行微调，生成具备对话功能的InstructGPT模型
- 数据处理：按照特定的对话模板格式，处理OpenHermes数据集，整理为用户&模型回答的对话格式，将其切分为训练集和测试集
- 模型量化：为了提升模型的运行效率，将原7B模型进行4bit量化，并采用bf16参数格式，既减少了模型的存储空间，也保持了模型的性能
- 模型训练：通过设置优化的训练超参数，并采用LoRA技术对每个注意力机制的QKVO共四矩阵增加参数层，对基座模型进行了精准的微调训练
- 模型效果：经过5个epoch，模型在HuggingFace的open-llm-leaderboard评估中，准确率达到63%，mc2达到42%，展示了模型优异的学习能力和稳定的性能

todo
多机多卡尝试操作训练

突出要点：Fine-tune

## 项目二

简介：基于RAG的Chatbot多轮对话

详细内容：

- 文档处理与向量化：处理企业知识库文档，尝试多种文档切分策略，选定一种高效的向量化模型对知识库文档进行处理，以实现最佳的数据准备
- 向量数据库配置与索引构建：配置Milvus的数据模式，将向量化的知识库文档数据灌入Milvus向量数据库，构建高效的ANNS（近似最近邻搜索）索引，以支持高速的数据检索。
- 检索增强与排序优化：通过开发一种基于RRF（融合排序）算法的检索后排序机制，结合关键词搜索与向量检索的混合检索方式，对知识库文档问答的用户输入进行RAG的检索增强
- RAG技术的应用：相较于依赖模型的通用能力，使用RAG后，模型的输出结果更加自然、准确，很大程度减小模型幻觉的出现，显著提升对用户输入的响应准确性和体验

突出要点：RAG

## 项目三

简介：基于提示词工程的雅思口语模拟考官

详细内容：

- 通过引入提示词工程技术，赋能雅思口语仿真模拟考试项目，实现高度仿真的口语模拟考试对话流程
- 在LangChain框架，综合使用LLaMa2-13B和Mistral-7B模型，结合业务需要设计Prompt提示词，通过LCEL语言将大模型、提示词、输出格式等内容进行结合
- Prompt调优：采用few-shot、思维链、Coze平台等方式，设计了具体、丰富且几乎无歧义的提示词，实现问答识别、问题生成、自然对话等模考功能，提升模拟考试的真实感和效果
- 防止Prompt攻击：通过使用用户输入检测算法、构建Prompt注入分类器、设计提示词、模型输出结果检测算法等多重措施，防止恶意内容的攻击，显著增强项目的鲁棒性
- 使用LangSmith测试和评估模型效果，跟踪其使用情况和输出结果，确保项目质量的持续优化和改进

突出要点：Prompt工程

本项目致力于通过引入提示词工程技术，赋予雅思口语仿真模拟考试项目新的能力，实现了一个高度仿真的口语模拟考试对话流程。项目在LangChain框架下，综合运用了LLaMa2-13B和Mistral-7B这两款大型语言模型。通过精心设计的Prompt提示词和LCEL语言，我们成功地将大模型的处理能力、业务需求、以及输出格式紧密结合起来。

在Prompt提示词的调优过程中，我们采用了few-shot学习、思维链技术、以及Coze平台等多种方法，设计了具体、丰富且几乎无歧义的提示词。这些提示词不仅能够有效地识别问答，还能生成问题，实现自然流畅的对话，从而提升模拟考试的真实感和效果。

针对Prompt攻击的潜在风险，我们通过引入用户输入检测算法、构建Prompt注入分类器以及设计提示词和模型输出结果的检测算法等多重措施，有效防止了恶意内容的攻击，显著增强了项目的鲁棒性。

此外，项目还使用了LangSmith工具对模型的效果进行测试和评估，并跟踪记录了其使用情况和输出结果，确保了项目质量的持续优化和改进。
