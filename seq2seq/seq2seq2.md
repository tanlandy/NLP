Goal:
1. 什么是seq2seq模型？
    - 输入一个序列，输出另一个序列机器翻译为例，序列是一串单词
    - 模型由编码器和解码器组成
      - 编码器处理输入序列的每个元素，转换成一个黄色的context向量
      - 处理完整个输入序列后，解码器通过那一个context向量，逐个生成输出序列
2. 基于RNN的seq2seq模型如何处理文本/长文本序列?
    - 编码器把序列的所有信息都编码到了一个context向量中。
      - 单个向量很难包含所有文本序列的信息
      - 处理长文本序列时，编码器的信息压缩能力有限，导致模型效果不佳
3. 基于RNN的seq2seq模型如何结合attention来改善模型效果？
    - attention机制：解码器在生成每个单词时，不仅仅依赖于context向量，还会根据当前生成的单词和编码器的输出计算出一个权重，用于指导解码器生成下一个单词
      - 注意力机制使得seq2seq2模型可以有区分度，有重点地关注输入序列


![](../imgs/1-6-seq2seq-decoder.gif) 动态图：编码器首先按照时间步依次编码每个法语单词，最终将最后一个hidden state也就是context向量传递给解码器，解码器根据context向量逐步解码得到英文输出。

## 带注意力的seq2seq模型
### 变化1: 更多信息传递给解码器
![](../imgs/1-6-mt-1.gif) 编码器把所有时间步的 hidden state（隐藏层状态）传递给解码器，而不是只传递最后一个 hidden state（隐藏层状态）

### 变化2: attention处理
- 解码器在t==4时间，查看h0-h3的hidden state
- 给每个hidden state计算一个分数
- 所有hidden state分数做softmax归一化
- 用归一化的分数作为权重，放大高分缩小低分
- 对所有hidden state做加权平均，得到一个context向量

![](../imgs/1-7-attention-dec.gif)动态图：在第4个时间步，编码器结合attention得到context向量的5个步骤。

### 可视化注意力机制

解码器在t==4时间（解码得到第一个输出）
1. 注意力模型的解码器 RNN 的输入包括：一个word embedding 向量，和一个初始化好的解码器 hidden state，图中是$h_{init}$。
2. RNN 处理上述的 2 个输入，产生一个输出和一个新的 hidden state，图中为h4。
3. 注意力的步骤：我们使用编码器的所有 hidden state向量和 h4 向量来计算这个时间步的context向量（C4）。
4. 我们把 h4 和 C4 拼接起来，得到一个橙色向量。
5. 我们把这个橙色向量输入一个前馈神经网络（这个网络是和整个模型一起训练的）。
6. 根据前馈神经网络的输出向量得到输出单词：假设输出序列可能的单词有N个，那么这个前馈神经网络的输出向量通常是N维的，每个维度的下标对应一个输出单词，每个维度的数值对应的是该单词的输出概率。
7. 在下一个时间步重复1-6步骤。

![](../imgs/1-7-attention-pro.gif)动态图：解码器结合attention全过程
