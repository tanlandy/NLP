{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标量\n",
    "标量由普通小写字母表示，例如 $x$，$y$，$z$。\n",
    "\n",
    "$\\mathbb{R}$ 为连续实数空间。\n",
    "$x \\in \\mathbb{R}$ 表示 $x$ 是一个实值标量的正式方式。\n",
    "\n",
    "标量由只有一个元素的张量表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向量\n",
    "\n",
    "向量可以视作由标量值组成的列表。这些标量值被称为向量的元素。\n",
    "\n",
    "向量通常记为粗体小写字母，例如 $\\mathbf{x}$，$\\mathbf{y}$，$\\mathbf{z}$。\n",
    "\n",
    "向量一般由一维张量表示\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以通过张量的索引来访问元素\n",
    "x[3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 长度、维度和形状\n",
    "数学表示法中，一个向量 $\\mathbf{x}$ 由n个实值标量组成，可以将其表示为 $\\mathbf{x} \\in \\mathbb{R}^n$。\n",
    "\n",
    "向量 $\\mathbf{x}$ 中的元素可以通过索引访问，例如 $\\mathbf{x}$ 中第 $i$ 个元素表示为 $x_i$。\n",
    "\n",
    "向量的长度称为向量的 *维度* (dimension)，是向量元素的数量。在代码中，向量的长度可以通过 Python 中的 `len()` 函数来访问。\n",
    "\n",
    "当用张量表示一个向量（只有一个轴）时，我们也可以通过.shape属性访问向量的长度。 形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数）。 对于只有一个轴的张量，形状只有一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x))\n",
    "x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 点积Dot Product\n",
    "\n",
    "点积是相同位置元素的乘积的和，例如 $\\mathbf{x}$, $\\mathbf{y} \\in \\mathbb{R}^n$ 的点积为 $\\mathbf{x}^T \\mathbf{y} = \\sum_{i=1}^{n} x_i y_i$。\n",
    "\n",
    "将两个向量规范化得到单位长度后，点积表示他们夹角的余弦。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵-向量积\n",
    "矩阵-向量积是一个矩阵和一个向量的积\n",
    "\n",
    "矩阵$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ 和向量$\\mathbf{x} \\in \\mathbb{R}^{n}$ 的矩阵-向量积是一个向量$\\mathbf{y} \\in \\mathbb{R}^{m}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵Hadamard积\n",
    "\n",
    "矩阵Hadamard积是两个矩阵的对应位置的元素相乘得到的矩阵"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵乘法matrix multiplication\n",
    "\n",
    "矩阵$\\mathbf{A} \\in \\mathbb{R}^{n \\times k}$ 和 $\\mathbf{B} \\in \\mathbb{R}^{k \\times m}$\n",
    "\n",
    "矩阵乘法$\\mathbf{C} = \\mathbf{A}\\mathbf{B} \\in \\mathbb{R}^{n \\times m}$，可以看作执行了$m$次矩阵-向量积，每次使用$\\mathbf{A}$ 乘以$\\mathbf{B}$ 的一列。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 范数norm\n",
    "\n",
    "向量范数是将向量映射到标量的函数$f$\n",
    "\n",
    "不正式地说，向量的*范数*衡量从原点到向量尖端的距离。不涉及维度，而是分量的大小\n",
    "\n",
    "### 范数的性质\n",
    "\n",
    "1. $\\forall \\alpha \\in \\mathbb{R}, f(\\alpha \\mathbf{x}) = |\\alpha| f(\\mathbf{x})$  范数随元素缩放而缩放\n",
    "2. $f(\\mathbf{x} + \\mathbf{y}) \\leq f(\\mathbf{x}) + f(\\mathbf{y})$  三角不等式\n",
    "3. $f(\\mathbf{x}) = 0 \\Leftrightarrow \\mathbf{x} = \\mathbf{0}$  所有范数非负\n",
    "\n",
    "### L1范数\n",
    "\n",
    "$L_1$ 范数表示为向量元素的绝对值之和\n",
    "\n",
    "$\\parallel \\mathbf{x} \\parallel = \\sum_{i=1}^{n} |x_i| $\n",
    "\n",
    "```py\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.abs(u).sum()\n",
    "```\n",
    "\n",
    "### L2范数\n",
    "\n",
    "$L_2$ 范数表示为向量元素的平方和的平方根\n",
    "\n",
    "$\\parallel \\mathbf{x} \\parallel _2 = \\sqrt{\\sum_{i=1}^{n} x_i^2} $\n",
    "\n",
    "```py\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)\n",
    "```\n",
    "\n",
    "\n",
    "### 范数的目标\n",
    "\n",
    "在深度学习中，我们经常试图解决优化问题： 最大化分配给观测数据的概率; 最小化预测和真实观测之间的距离。 \n",
    "\n",
    "用向量表示物品（如单词、产品或新闻文章），以便最小化相似项目之间的距离，最大化不同项目之间的距离。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
