17. Transformer的优缺点
优点：
可并行
独立于卷积和循环，完全依赖于attention处理全局依赖，解决长距离依赖问题
性能强

缺点：
长度固定
局部信息的获取不如RNN和CNN强：Transformer关注的全局关系，而RNN在计算过程中更关注局部，对距离更加敏感。

18. Transformer Encoder 有什么子层？（超参数一面）
Encoder由六个相同层构成，每层都有两个子层：多头自注意力层和全连接的前馈神经网络层（Linear+relu+dropout+Linear）。使用残差连接和层归一化连接两个子层。

19. Decoder阶段的多头自注意力和encoder的多头自注意力有什么区别？/ 为什么decoder自注意力需要进行sequence mask？
让输入序列只看到过去的信息，而看不到未来的信息。

20. Transformer、LSTM和单纯的前馈神经网络比，有哪些提升？
LSTM相比于单纯的前馈神经网络，首先具有理解文本的语序关系的能力（RNN）。除此之外，又解决了RNN在处理长序列时发生的梯度消失和梯度爆炸的问题。

Transformer进一步解决了RNN、LSTM等模型的长距离依赖问题，能够理解更长的上下文语义。可以并行化，所要的训练时间更短。

21. 两种策略将预训练的语言表示应用到下游任务：
基于特征 (feature-base)：将训练出的表示作为feature用于任务。
微调 (fine-funing)：在预训练好的模型上加些针对任务的层，再对后几层进行精调。

22. Word2vec (feature-base)

22.1 说说word2vec？
语言离散表示的缺点：
维度过高，数据稀疏，难以优化
不包含语义，无法衡量词与词之间的关系

word2vec是一种分布式表示。（为什么叫分布式表示：相比于one-hot只有一个维度是1，将词的表示集中在某个维度，分布式表示将词的信息分散到每个维度。）

word2vec是从大量文本语料中以无监督的方式学习语义知识的一种模型，通过一个嵌入空间使得语义上相似的单词在该空间中距离很近。 基本流程：先基于训练数据构建一个神经网络，当模型训练好之后，用这个模型通过训练数据所学到的参数，如隐层的权重矩阵，作为词向量。 模型的输出概率代表了词典中每个词有多大的概率跟input word同时出现。

22.2 word2vec为什么通过单词预测可以学习到单词的embedding？
无监督的学习方式，利用上下文语言环境学习词的嵌入表示。通过一个嵌入空间，使得语义上相似的单词再该空间内距离很近。

22.3 两种原理/框架
skip-gram和CBOW的训练目标都不是得到一个预测上下文词的模型，而是作为一种预训练任务，得到词向量。
22.3.1 skip-gram \ 给定input word预测上下文。
输入层：一个单词的词向量。

投影层：没有操作，直接将输入的词向量传向输出层。 如果需要用300维的向量表示词向量，则隐层需要有300个节点，隐层矩阵为10000行，300列（10000为词汇数，300为隐层个数）。最终目标就是学习隐层的权重矩阵（10000x300） 模型训练完毕，直接查询word对应的index所在行的向量，即为输入单词的词嵌入。 如果两个词具有非常相似的上下文，那么他们的嵌入向量也会非常相似。

输出层：每个单词都是相互独立的，没有顺序关系，共享权重矩阵。
22.3.2 CBOW \ 用中心词的C个上下文单词，预测中心词。
输入层：上下文的词向量。

投影层：每个上下文使用的权重矩阵是共享的，且该层不使用激活函数。投影层对输入进行向量相加求平均值的操作。

输出层：输出最可能的w。可以看做一个对分类问题，最朴素的做法是softmax回归。

23. GPT (fine-funing)
可迁移到多种NLP任务的，基于Transformer的语言模型。 模型的训练分两步：

无监督的预训练 目标函数是最大化似然函数。
有监督的训练数据
优点：
循环神经网所捕获到的信息较少，而transformer可以捕获到更长范围的信息。
计算速度比循环神经网络更快，易于并行化
实验结果显示，Transformer的效果比ELMo和LSTM网络更好

缺点： 对于某些类型的任务需要对输入数据的结构作调整。

24. 梯度消失和梯度爆炸
多个激活函数偏导数的连乘，和多个权重参数的连乘。如果激活函数求导后与权重相乘的积大于1，那么随着层数增多，求出的梯度更新信息将以指数形式增加，即发生梯度爆炸；如果此部分小于1，那么随着层数增多，求出的梯度更新信息将会以指数形式衰减，即发生梯度消失。

防止梯度爆炸：
梯度剪切：更新梯度时，梯度超过某个阈值，就将其强制限制在这个范围内
权重正则化：L1正则和L2正则

防止梯度消失：
合理的激活函数（如ReLU）+权重初始化
Batch Normalization：应用于每层激活函数之前
残差网络

25. 欠拟合 / 过拟合
欠拟合
是指模型不能在训练集上获得足够低的误差，即，模型在训练集上表现很差，没有学习到数据背后的规律。

解决欠拟合的方法
添加新特征，挖掘“上下文特征”、“组合特征”
增加模型复杂度
减少正则化系数

过拟合
训练误差和测试误差之间的差距太大，即，模型在训练集上表现很好，但在测试集上表现很差，模型泛化能力差。

如何判断过拟合
可以通过查看训练集误差和验证集误差的方式查看过拟合，如果训练集误差和验证集误差差距大，训练集误差在下降，而验证集误差在上升，则可能是过拟合了。

解决过拟合的方法
交叉验证，通过交叉验证得到较优的模型参数
特征选择，减少特征数或者使用较少的特征组合，对于按区间离散化的特征，增大划分区间。（当样本特征数很多，而样本数很少的时候，很容易陷入过拟合。可以以多元方程式为例，样本少时，如果方程式中的参数越多，越容易过拟合。）
正则化，常用的有L1、L2正则。而且L1正则化可以自动进行特征选择；如果有正则项可以考虑增大正则项参数lambda。
增加训练数据可以有效的避免过拟合。减少了噪声的影响。
bagging，将多个弱分类器bagging一下效果会更好，比如随机森林等。
随机森林：由多个决策树组成，每个决策树不相同。
随机：
样本随机 - 构建决策树时使用重采样；
特征随机 - 不会使用数据的全部特征。
优点：善于处理特征遗失数据、不平衡数据、高维数据
降低模型复杂度。
正则化为什么可以解决过拟合
主要原理是通过引入权重参数来限制模型复杂度，从而提高模型的泛化能力。正则化可理解为是一种“罚函数法”，即对不希望得到的结果施以惩罚，从而使得优化过程趋向于希望目标。

为什么提前停止可以解决过拟合问题
提前终止是指：在测试误差开始上升之前，就停止训练,即使此时训练尚未收敛(即训练误差未达到最小值)。

-------------------------------------------------------------------------------------------------------------------

26. 简单介绍下Transformer
是一种基于注意力机制的神经网络模型。Transformer模型由编码器和解码器两部分组成，其中编码器用于将输入序列编码成一个高维向量表示，解码器用于将这个向量表示解码成目标序列。Transformer模型最核心的部分是自注意力机制，它能够让模型在不同位置之间进行信息传递和交互，从而更好地学习输入序列中的信息。

27. Transformer是输入是什么？
输入是词向量与位置向量之和，词向量可以通过预训练的词向量模型或在模型内部学习得到。位置向量可以通过固定位置编码公式获得或者在模型内容不学习得到

28. 固定位置编码和可学习位置编码优缺点？
固定位置编码优点是可以根据公式快速获得句子的位置信息，无需在训练中继续学习；其缺点是不能处理变化的序列（例如：我是大帅哥，大帅哥是我）。可学习位置编码优点是可以通过训练时动态理解句子的位置信息；缺点是需要大量的数据才能获取比较全的位置信息。

29. 为何在获取输入词向量之后需要对矩阵乘以embedding size的开方？意义是什么？
embedding matrix的初始化方式是xavier初始化，这种方式的方差是1/embedding size，因此乘以embedding size的开方使得embedding matrix的方差是1，在这个scale下可能更有利于embedding matrix的收敛。

30. 大概讲一下Transformer的Encoder模块？
Transformer的Encoder模块是由多个相同的层堆叠而成的，每一层由两个子层组成，分别是多头注意力机制（Multi-Head Attention）和前馈神经网络（Feed-Forward Neural Network）。在多头注意力机制中，输入序列会经过三个线性变换，分别是Q、K、V，然后进行多头注意力计算，得到每个位置对其他位置的注意力权重，再将输入序列加权求和得到多头注意力的输出。在前馈神经网络中，多头注意力的输出经过两个全连接层和ReLU激活函数的变换，得到每个位置的特征表示。接下来，这两个子层会进行残差连接（Residual Connection）和层归一化（Layer Normalization）操作，使得模型更容易训练，也能更好地捕捉输入序列之间的相关性。

31. 为什么transformer块使用LayerNorm而不是BatchNorm？
Layer Normalization是一种能够应对不同序列长度的归一化方法，它对每个样本的特征进行归一化。Batch Normalization是一种在深度神经网络中广泛使用的归一化方法，通过对每个小批量的输入进行归一化，从而使得网络的训练更加稳定，并加速收敛速度。但是，在自然语言处理任务中，输入的序列长度通常是不同的，因此很难将不同长度的序列组成一个小批量进行归一化。

32. Transformer输入只能相加吗
在Transformer模型中，输入的两个部分是词向量和位置编码，它们是分别生成的，然后进行相加得到最终的输入表示。因此，在Transformer模型中，输入确实只能相加，即词向量和位置编码不能进行其他的运算，如乘法、除法等。这是因为词向量和位置编码的维度是相同的，都是模型的隐藏层维度，而它们的作用是不同的，词向量用于表示单词的语义信息，位置编码用于表示单词在句子中的位置信息。因此，将它们相加可以将这两种信息融合到一起，从而为模型提供更加丰富的输入信息。如果进行其他的运算，如乘法、除法等，可能会破坏词向量和位置编码的信息，影响模型的性能。因此，在Transformer模型中，输入只能相加，不能进行其他的运算。

33. Transformer为何使用多头注意力机制？
 提高模型的表达能力，多头注意力机制可以让模型在不同的注意力空间下学习到不同的特征，从而能够更好地表达输入序列的信息。如果只使用一个注意力头，那么模型可能会在学习特定的特征时出现瓶颈，导致模型的表达能力受限。

34. Transformer为什么Q和K使用不同的权重矩阵生成，为何不能使用同一个值进行自身的点乘？

答： 在Transformer中，Q和K使用不同的权重矩阵生成是为了让模型在学习不同的特征时更加灵活。Q和K的区别在于它们所代表的信息不同，Q代表查询信息，K代表键信息，它们的作用不同，因此使用不同的权重矩阵可以让模型在不同的注意力空间下学习到更加丰富的特征，并提高模型的表现能力。如果使用同一个权重矩阵进行自身的点乘操作，可能会使模型在学习特定的特征时出现瓶颈，导致模型表达能力受限，从而影响模型的性能。

35.Transformer计算attention的时候为何选择点乘而不是加法？

答： 在Transformer中，采用点乘（dot-product）作为注意力机制的计算方式，是因为点乘计算的方式是一种更加有效的方法，可以更好地捕捉输入序列中的相关性。与加法相比，点乘可以使模型在计算注意力时更加精确，同时也具有更好的计算效率。

36.在计算attention时，为什么进行softmax之前需进行scaled（为什么除以dk的平方根）?

答： 在计算self-attention时，需要进行softmax操作，以计算每个输入序列位置对其他位置的注意力权重。为了避免softmax函数的指数计算导致数值溢出或下溢，Transformer模型中使用了scaled dot-product attention，即在softmax之前对向量点乘结果进行了缩放操作，用于控制点乘结果的大小。
具体来说，该缩放操作是将点乘结果除以一个值，这个值是输入向量的维度的平方根，即dk的平方根，其中dk表示每个向量的维度。这个缩放因子的作用是：当输入向量的维度增加时，点乘结果的大小也会增加，导致softmax函数的指数计算变得困难，缩放因子能够使点乘结果的大小保持在一个合适的范围内，从而提高计算的稳定性。

37.大概讲一下Transformer的Decoder模块？

答： Transformer模型的Decoder模块是用于将Encoder模块的输出映射到目标序列的一组连续表示的核心部分。该模块由多个Decoder层组成，每个Decoder层包括了以下几个部分：

自注意力层：与Encoder中的自注意力层类似，Decoder中的自注意力层也是将输入序列中每个位置的表示向量作为查询向量、键向量和值向量，通过多头注意力计算得到每个位置的上下文向量。
编码器-解码器注意力层：该层用于将Encoder模块的输出与Decoder中上一层的输出结合起来，以便更好地理解输入和输出之间的关系。具体来说，该层将Encoder模块的输出作为键向量和值向量，将Decoder中上一层的输出作为查询向量，通过多头注意力机制计算得到每个位置的上下文向量。
前馈神经网络层：该层对经过自注意力层和编码器-解码器注意力层编码的信息进行非线性变换，以提高模型的表达能力。
残差连接层和层归一化层：这两个层与Encoder模块中的残差连接层和层归一化层类似，用于保证模型的稳定性和加速训练。在每个Decoder层之间，都进行了层归一化处理。
Decoder模块的最后一层输出的表示向量经过一个线性变换和softmax函数，得到每个位置上每个单词的概率分布。然后可以根据分布进行单词的选择和预测。

38. Decoder阶段的多头自注意力和encoder的多头自注意力有什么区别？

答： 在Transformer模型中，Encoder和Decoder都包含多头自注意力机制。虽然它们的原理类似，但是在具体实现中，它们之间存在一些区别。下面分别介绍Decoder阶段的多头自注意力和Encoder的多头自注意力的区别：
1.查询向量不同：在Encoder的多头自注意力中，每个词向量都被用作查询、键和值，即Q = K = V Q=K=VQ=K=V，而在Decoder的多头自注意力中，查询向量是上一个Decoder层的输出，而键和值向量是Encoder模型的输出。
2.掩码：在Decoder的多头自注意力中，需要使用掩码来防止当前时间步的解码器看到未来时间步的信息。具体来说，将未来时间步的位置的注意力权重设置为0，这样在计算当前时间步的注意力分数时，就不会考虑未来时间步的信息。
3.添加编码：在Decoder的多头自注意力中，需要将编码器的输出添加到查询向量和键向量中，以便解码器能够了解输入序列的信息。
4.位置编码：在Decoder的多头自注意力中，位置编码的计算方式与Encoder中的位置编码不同。Encoder中的位置编码是为了表示输入序列中单词的位置关系，而Decoder中的位置编码是为了表示输出序列中单词的位置关系。

39.Transformer的并行化体现在哪个地方？Decoder端可以做并行化吗？

答：

1. 多头注意力机制：多头注意力机制将输入序列分成多个子序列，并同时计算每个子序列的注意力表示，从而实现了多头并行计算。这种并行计算方式可以有效地加速模型的训练和推理过程。
2. Encoder端的并行化：在Encoder端，Transformer模型将输入序列分成多个子序列，并分别在不同的计算设备上进行计算。这种并行计算方式可以显著提高模型训练的速度。
而在Decoder端，由于每个时间步的计算需要依赖上一个时间步的输出，因此无法进行完全的并行化。但是，可以通过一定的技巧来提高Decoder的并行化效率，例如：
3. 延迟解码：在训练时，可以将目标序列分成多个子序列，并在不同的计算设备上同时进行解码。但是，在推理时，由于无法知道整个目标序列，因此需要使用延迟解码的方式，即在每个时间步上进行解码，并将上一个时间步的输出作为当前时间步的输入。
4. Beam Search并行化：在推理时，可以使用Beam Search算法来生成目标序列，并通过将不同的Beam分配到不同的计算设备上来实现推理的并行化。
因此，虽然Decoder端无法像Encoder端那样进行完全的并行化，但是可以通过一定的技巧来提高其并行化效率。

40. 简单描述一下Transformer中的前馈神经网络？使用了什么激活函数？相关优缺点？

答： Transformer模型中的前馈神经网络（Feed-Forward Neural Network，简称FFN）是在每个Encoder和Decoder层的自注意力层和编码器-解码器注意力层之间添加的一层全连接的前馈神经网络。它的输入是自注意力层或编码器-解码器注意力层的输出，输出是一个新的表示向量，其中包含了更高层次的语义信息。
在Transformer模型中，FFN使用了两层全连接的结构，两层之间使用了ReLU激活函数。具体来说，在每个FFN层中，输入的表示向量首先通过一个全连接层进行线性变换，然后再通过一个ReLU激活函数进行非线性变换，最后再通过另一个全连接层进行线性变换得到输出。
FFN的优点是可以通过多层的非线性变换，提取输入的更高层次的语义特征，从而提高模型的表达能力。另外，由于FFN的计算是独立进行的，因此可以通过并行化来加速模型的训练和推理过程。
但是，FFN也存在一些缺点。首先，由于FFN只考虑了每个位置的局部信息，因此无法处理序列中的长距离依赖关系。其次，由于FFN的计算复杂度较高，因此容易成为模型的瓶颈。最后，由于FFN没有考虑序列中的位置信息，因此可能会存在位置信息的混淆问题。
为了解决这些问题，一些变种的Transformer模型，如XLNet和Relative Positional Encoding等，引入了新的机制，以提高模型的性能和稳定性。

---------------------------------------------------------------------------------------

41. Fine-tuning / Embedding
Fine-tuning: Teach the model how to answer a question (e.g. structure/format, personality, etc)
Embedding: Provide the model with new/specific information with which to answer questions

42. L1 / L2
<https://zhuanlan.zhihu.com/p/352437358>

44. Metrics
<https://blog.csdn.net/qq_44783689/article/details/121665297>
<http://www.360doc.com/content/22/1213/09/40892371_1060069718.shtml>

44. RNN vs LSTM
<https://blog.csdn.net/YoungDo_02/article/details/88067441?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-88067441-blog-77185225.235%5Ev38%5Epc_relevant_sort_base3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-88067441-blog-77185225.235%5Ev38%5Epc_relevant_sort_base3&utm_relevant_index=2>

45. 请讲一下在训练神经网络的时候，有哪些常见的优化算法，各自有什么优缺点？
<https://zhuanlan.zhihu.com/p/458968689>

46. 目前常用的微调方法包括Freeze，P-tuning和LoRA

47.

模型      模型结构       位置编码 激活函数     layer norm
LLaMA     Casual decoder RoPE SwiGLU     Pre RMS Norm
ChatGLM-6B  Prefix decoder RoPE GeGLU     Post Deep Norm

49.XGBoost
<https://blog.csdn.net/shanlijia/article/details/120627427>

50.epoch，batch, batch_size, iteration等
<https://blog.csdn.net/weixin_41529012/article/details/116293963?spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-116293963-blog-81872663.235%5Ev39%5Epc_relevant_yljh&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-116293963-blog-81872663.235%5Ev39%5Epc_relevant_yljh&utm_relevant_index=15>

batch_size:
<https://blog.csdn.net/jiachang98/article/details/124729988?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124729988-blog-81872663.235%5Ev39%5Epc_relevant_yljh&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124729988-blog-81872663.235%5Ev39%5Epc_relevant_yljh&utm_relevant_index=2>

52. Q-learning
Q-learning是一种强化学习算法，用于解决马尔可夫决策过程（MDP）中的问题。它是一种value-based（基于值）的算法，通过构建一个Q表来存储每个状态和动作的Q值，从而指导智能体在不同状态下采取最优的行动。Q值表示在某个状态下采取某个动作所能获得的期望收益。

Q-learning的主要优势在于它能够进行off-policy（离策略）的学习，即在学习过程中不需要对环境进行建模，也不需要特别改动带有随机因素的转移函数或奖励函数。它使用时间差分法（融合了蒙特卡洛和动态规划）来更新Q值，并使用贝尔曼方程来求解最优策略。

Q-learning的算法思想可以通过一个简单的例子来说明。假设有一个探险者在一维世界中寻找宝藏。探险者可以在每个位置上采取左移或右移两种行动。在每个位置上，探险者根据之前的经验（Q表）选择能够获得最大收益的行动。通过不断更新Q表中的Q值，探险者逐渐学习到在不同位置下采取不同行动的最优策略。

Q-learning的算法公式可以总结如下：

Q(s, a) = (1 - α) *Q(s, a) + α* (r + γ * maxQ(s'))
其中，Q(s, a)表示在状态s下采取行动a的Q值，α是学习率，γ是对未来奖励的衰减因子，r是当前状态下的奖励，maxQ(s')表示在下一个状态s'下所有可能行动的最大Q值。
Q-learning还有一些参数需要设置：

Epsilon贪婪度：用于决策的策略，表示在多大程度上采用Q表的最优值，剩余的部分随机选择行动。
学习率α：决定本次更新中有多少误差需要被学习。
奖励衰减因子γ：对未来奖励的衰减程度，越接近1表示对未来奖励越敏感。

53. DQN算法基本沿袭了Q-learning的思想，只不过为了能够与深度神经网络结合，而做了一些改进的装饰 [1]：

增加记忆库：如上图中的第⑤步，记忆库的作用是可以用于重复学习，正如同背单词，单词要重复背才能够记得深刻。
利用神经网络计算Q值：如上图中的第8.4步，这一步的思想和Q-learning的计算Q值的思想是一致的，利用预测网络计算预测值，利用目标网络计算目标值，两者之间的误差，用来更新预测网络的参数。
暂时冻结目标网络：如上图的第8.2步，由于在强化学习中，连续获得的观测值之间往往是有相关性的，比如，今天背的单词中很有可能有一部分是昨天背的单词，为了断绝这种数据的相关性，需要复制一份大脑Y出来，即为目标网络，这个大脑Y的结构与现实的大脑X是一样的，但是不会每一步都更新为大脑X。那么，当大脑X在碰到十天前记的单词时，预测的单词释义到底对不对呢，就可以用十天前复制的大脑Y来检验了。也就是说，目标网络就是用来检验预测网络的Q值是否预测的正确，如果不正确，就更新预测网络参数。

54. 交叉验证
以下是几种常见的交叉验证方法：

K折交叉验证（K-fold Cross Validation）：将数据集分成K个子集，每个子集轮流作为测试集，其余子集作为训练集。重复K次，每次选择一个子集作为测试集，并将K次的平均性能作为结果[2]。

留一交叉验证（Leave-One-Out Cross Validation，LOOCV）：假设数据集中有n个样本，那么LOOCV将每个样本单独作为一次测试集，剩余n-1个样本作为训练集。这种方法的优点是每一回合中几乎所有的样本都用于训练模型，因此估测的泛化误差比较可靠。但是计算成本较高，适用于样本数量较少的情况[2]。

K *2折交叉验证（K* 2-fold Cross Validation）：是K折交叉验证的一个变体，对每一个fold，将数据集平均分成两个集合，然后在这两个集合上进行训练和测试。这种方法的优点是训练集和测试集都足够大，每个样本都被用于训练和测试[2]。

k-fold注意事项
数据集划分：在进行K-fold交叉验证时，需要将数据集划分为K个子集。确保划分后的子集之间是相互独立且没有重叠的，以避免数据泄露和重复使用数据的问题。

数据分布：在进行K-fold交叉验证时，需要确保每个子集中的数据分布与整个数据集的分布相似。这样可以保证模型在每个子集上的训练和测试都能够代表整个数据集的特征。

模型选择：在进行K-fold交叉验证时，需要选择合适的模型进行训练和测试。不同的模型可能对数据集的特征有不同的适应性，因此需要根据具体问题选择合适的模型。

超参数调优：在进行K-fold交叉验证时，可以通过调整模型的超参数来优化模型的性能。可以使用网格搜索等方法来寻找最佳的超参数组合。

结果评估：在进行K-fold交叉验证时，需要对每个子集上的模型进行评估，并计算平均性能指标。常用的性能指标包括准确率、精确率、召回率、F1值等。

计算资源：在进行K-fold交叉验证时，需要考虑计算资源的限制。如果数据集较大或模型复杂，可能需要较长的计算时间和更多的计算资源。

56. ResNet

面试题 1: 解释ResNet中的残差学习（Residual Learning）是如何帮助训练深层网络的？
答案:
在深层网络中，梯度消失或爆炸是一个常见问题，这使得网络难以训练。ResNet通过引入残差学习来解决这个问题。在残差块中，输入不仅通过一系列卷积层传递，还通过跳跃连接直接传递到更深的层。这意味着深层网络可以学习到的是输入与输出之间的残差（即差异），而不是直接学习到未修改的输出。如果一个恒等映射是最优的，网络可以通过将残差设置为零来轻易实现，从而使得深层网络的训练变得更加容易。跳跃连接还帮助梯度直接流回更浅层，从而减轻了梯度消失的问题，使得训练更深的网络成为可能。

面试题 2: ResNet中的瓶颈层（Bottleneck Layer）有什么作用？
答案:
在ResNet的一些变种中，特别是用于深层网络的版本（如ResNet-50、ResNet-101和ResNet-152），使用了一种称为瓶颈层的设计。瓶颈层首先使用1x1卷积层减少输入的维度（深度），然后应用3x3卷积层进行特征提取，最后再用另一个1x1卷积层恢复维度。这种设计的目的是减少参数数量和计算量，同时保持网络性能。通过首先减少维度，网络可以在较小的维度空间内对特征进行更有效的处理，然后再将其映射回较高的维度空间。这样不仅提高了计算效率，而且有助于网络学习更加复杂和抽象的特征表示，从而提高了网络在各种视觉任务上的性能。
