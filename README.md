# NLP

All about NLP
学习和实践过程中的，与NLP相关的大本营

# 李沐精讲学习方式
看三遍
- 1X第一遍，记录下不会的东西
- 1.25X第二遍，做笔记，尽量全部看懂
- 1.5X第三遍，完善笔记，全部弄懂

# Roadmap

## Suggetions

[导师让我搞gpt方向，我该怎么去学？ - Uranus的回答 - 知乎](https://www.zhihu.com/question/604134581/answer/3063230236)


## Neural Network
[NN](https://youtu.be/BR9h47Jtqyw)
[RNN](https://youtu.be/UNmqTiOnRfg)



## Transformer

[Transformer论文精读](https://youtu.be/nzqlFIcCSWQ)
[Huggingface案例](https://github.com/huggingface/transformers/tree/main/examples)
[手把手有代码的教程](https://datawhalechina.github.io/learn-nlp-with-transformers/#/)
[知乎详解](https://zhuanlan.zhihu.com/p/403433120)

## GPT和大模型RLHF训练

DONE[Andrej Karpathy微软Build大会精彩演讲： GPT状态和原理 - 解密OpenAI模型训练](https://www.bilibili.com/video/BV1ts4y1T7UH/?share_source=copy_web&vd_source=1aea27c12a97d57f180ca22afea77cce)

[GPT论文精读](https://youtu.be/t70Bl3w7bxY)

[InstructGPT](https://youtu.be/zfIGAwD1jOQ)

### Instruct-fine-tuning

[Instruction finetuning and RLHF lecture](https://youtu.be/zjrM-MW-0y0)

[Slides for the lecture above](https://docs.google.com/presentation/d/13Tylt2SvKvBL2hgILy5CmBtPDv3rXlVrQp01OzAe5Xo/mobilepresent?slide=id.g238b2698243_0_1072)

## DeepSpeed

[DeepSpeed官网](https://www.deepspeed.ai/)

[DeepSpeed开手项目](https://www.deepspeed.ai/tutorials/azure/)

[DeepSpeed Chat中文](https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-chat/chinese/README.md)

[DeepSpeed Github](https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat#-quick-start-)

## LLaMA

[LLaMA official website](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)

[LLaMA Paper](https://arxiv.org/abs/2302.13971)

[Susan Zhang: Trails of developing OPT-175B](https://www.youtube.com/live/p9IxoSkvZ-M?feature=share)

[手把手用RLHF训练LLaMA](https://huggingface.co/blog/zh/stackllama)

## LoRA

## AIGC

[Colossal-AI](https://www.hpc-ai.tech/blog/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper)

### GAN

[GAN论文精读](https://youtu.be/g_0HtlrLiDo)

### DALL-E

[DALL-E论文精读](https://youtu.be/hO57mntSMl0)

### Diffusion

## Prompt

## OpenAI接口整活

[Chameleon](https://chameleon-llm.github.io/)

[Grammatical Error](https://arxiv.org/abs/2303.13648)

[ChatGPT NLG Evaluator](https://arxiv.org/abs/2303.04048)

# 面经

## LLM
1. ChatGPT Plugins体验。不足与提升
2. LLM做控制的局限，解决办法
3. 多模态有哪些思路
4. 视觉如何融入
5. LLM的输出输入如何审核？风险控制？
6. Langchain及原理
7. autogpt原理
8. 如何突破transformer token限制
9. 大语言模型有哪几种架构，哪几种最流行，为什么
10. 语言模型自监督有哪几种方法
11. prompt设计心得
12. 推理阶段有哪些提升chatgpt性能的方法
13. ChatGPT, GPT4的应用场景

## 神经网络基础
1. 计算基本神经网络的参数量rnn, cnn, transformer
2. 微调有哪几种方法？解释原理
3. adam原理。实现需要哪些依赖，是否有优化空间
4. 系统调用是什么？训练神经网络数据传输链路，哪里可以优化？
5. attention原理

## CS基础
1. 多进程和多线程的区别
2. hash表和最小堆原理以及实现
3. 排序算法有哪些，解释原理。基于比较的排序算法，理论最快时间复杂度是多少
4. 已知随机分布的均值和方差，求使得熵最大的概率分布
5. 进程间通信方法？线程见通讯方法

## 参考公司
1. Minimax
2. 王小川-五季智能
3. 周伯文-衔远科技
4. 慧文-光年之外
5. 昆仑万维
6. hoxi
7. 爱诗科技
8. 智元机器人
9. stability.ai
10. softbank
11. huggingface

